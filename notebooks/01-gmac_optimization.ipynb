{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GMAC Optimization: Grid search of GMAC parameters\n",
        "\n",
        "The GMAC algorithm has the following parameters required to map the raw acceleration\n",
        "data to the arm-use space. These parameters are:\n",
        "1. Moving average window size for pitch estimation. $\\left( n_{p} \\right)$\n",
        "2. Butteworth highpass filter cut-off for accl. mag. estimation. $\\left( f_{c} \\right)$\n",
        "3. Butteworth highpass filter order for accl. mag. estimation. $\\left( n_{c} \\right)$\n",
        "4. Acceleration deadband threshold. $\\left( a_{th0} \\right)$\n",
        "5. Moving average window for acceleration magnitude estimation. $\\left( n_{am} \\right)$\n",
        "6. Pitch angle hysteresis lower threshold. $\\left( \\theta_{min} \\right)$\n",
        "7. Pitch angle hysteresis upper threshold. $\\left( \\theta_{max} \\right)$\n",
        "8. Acceleration magnitude hysteresis lower threshold. $\\left( a_{min} \\right)$\n",
        "9.  Acceleration magnitude hysteresis upper threshold. $\\left( a_{max} \\right)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## GMAC Algorithm\n",
        "\n",
        "The GMAC algorithm is a combination of the gross movement (GM) algorithm and the \n",
        "activty counting (AC) algorithm. The GMAC algorithm, using only the accelerometer, \n",
        "tries to: (1) estimate the information used by GM and AC, forearm pitch angle and \n",
        "activity counts, respectively; and (2) applies thresholds on the estimated pitch \n",
        "and activity counting to estimate of the arm-use.\n",
        "\n",
        "### Pitch Estimation\n",
        "Pitch estimation is using the accelerometer data, and requies one to know the axis \n",
        "of accelerometer that is aligned with the forearm. The pitch is then estimated by \n",
        "estimating the arc-cosine of component of acceleration along this direction normalised \n",
        "by the magnitude of the acceleration due to gravity.\n",
        "\n",
        "### Activity Counting Estimation\n",
        "The activity counts is likely to be correlated to the magnitude of the highpass \n",
        "filtered acceleration.\n",
        "\n",
        "### Applying thresholds\n",
        "The pitch and activity counts are then thresholded to estimate the arm-use. \n",
        "Instead of applying a simple threshold algorithm that can be very sensitive to \n",
        "noise whenn the variable is close to the threshold, a thresholding procedure with \n",
        "hysteresis algorithm is used for both the pitch and the acceleration magnitude \n",
        "variables.\n",
        "\n",
        "### Parameter search ranges\n",
        "$F_s$ is the sampling frequency of the accelerometer data.\n",
        "1. $n_{p} \\in \\left\\{1, F_s/2, F_s, 2F_s, 5F_s\\right\\}$\n",
        "2. $f_{c} \\in [0.01, 0.1, 1]Hz \\subset \\mathbb{R}$\n",
        "3. $n_{c} \\in \\left\\{ 2, 4, 8\\right\\}$\n",
        "4. $n_{am} \\in \\left\\{1, F_s/2, F_s, 2F_s, 5F_s\\right\\}$\n",
        "5. $a_{th0} \\in \\left\\{ 0, 0.068, 0.68\\right\\}$\n",
        "6. $\\theta_{min}, \\theta_{max} \\in \\left\\{ 0, 20, \\ldots +180 \\right\\}\\deg$\n",
        "7. $a_{min}, a_{max} \\in \\left\\{0, 5, 10, 50, 100\\right\\}$"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Getting the data\n",
        "\n",
        "If you do not already have the data to run this this notebook, you need to\n",
        "download it from here.\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Standards modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import pearsonr\n",
        "import scipy\n",
        "from scipy import signal\n",
        "import pathlib\n",
        "import itertools\n",
        "import glob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import seaborn as sns"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "CmFNtZKR71KW"
      },
      "source": [
        "### Custom Modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjSXcfJ-8Pyq",
        "outputId": "ee0f6d9a-a224-4a12-f481-db1f6e0d50af"
      },
      "outputs": [],
      "source": [
        "sys.path.append(\"../scripts\")\n",
        "\n",
        "import classification_algorithms as ca\n",
        "import reduced_models as rm\n",
        "import task_analysis as ta\n",
        "\n",
        "import misc"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define notebook level constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sampling rate for the data is 50ms\n",
        "dT = 0.02\n",
        "Fs = int(1 / dT)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Read the Controls and Patients Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "mSMQTzY48cme"
      },
      "outputs": [],
      "source": [
        "# Read healthy and control data\n",
        "left, right = misc.read_data(subject_type='control')\n",
        "aff, unaff = misc.read_data(subject_type='patient')\n",
        "\n",
        "# Assign segments for each subject\n",
        "left = pd.concat([misc.assign_segments(left[left.subject == subj], dur_th=1, dT=dT)\n",
        "                  for subj in left.subject.unique()], axis=0)\n",
        "right = pd.concat([misc.assign_segments(right[right.subject == subj], dur_th=1, dT=dT)\n",
        "                   for subj in right.subject.unique()])\n",
        "aff = pd.concat([misc.assign_segments(aff[aff.subject == subj], dur_th=1, dT=dT)\n",
        "                 for subj in aff.subject.unique()])\n",
        "unaff = pd.concat([misc.assign_segments(unaff[unaff.subject == subj], dur_th=1, dT=dT)\n",
        "                   for subj in unaff.subject.unique()])\n",
        "\n",
        "# All limbs data ddf\n",
        "datadf = {\n",
        "    \"left\": left,\n",
        "    \"right\": right,\n",
        "    \"aff\": aff,\n",
        "    \"unaff\": unaff\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Functions implementing the GMAC algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def estimate_pitch(accl_farm: np.array, nwin: int) -> np.array:\n",
        "    \"\"\"\n",
        "    Estimates the pitch angle of the forearm from the accelerometer data.\n",
        "    \"\"\"\n",
        "    # Moving averaging using the causal filter\n",
        "    acclf = signal.lfilter(np.ones(nwin) / nwin, 1, accl_farm) if nwin > 1 else accl_farm\n",
        "    acclf[acclf < -1] = -1\n",
        "    acclf[acclf > 1] = 1        \n",
        "    return -np.rad2deg(np.arccos(acclf)) + 90\n",
        "\n",
        "\n",
        "def estimate_accl_mag(accl: np.array, fs: float, fc: float, nc: int,\n",
        "                      deadband_th: float, n_am: int) -> np.array:\n",
        "    \"\"\"\n",
        "    Compute the magnitude of the accelerometer signal.\n",
        "    \"\"\"\n",
        "    # Highpass filter the acceleration data.\n",
        "    sos = signal.butter(nc, fc, btype='highpass', fs=fs, output='sos')\n",
        "    accl_filt = np.array([signal.sosfilt(sos, accl[:, 0]),\n",
        "                          signal.sosfilt(sos, accl[:, 1]),\n",
        "                          signal.sosfilt(sos, accl[:, 2])]).T\n",
        "    \n",
        "    # Zero load acceleration components.\n",
        "    accl_filt[np.abs(accl_filt) < deadband_th] = 0\n",
        "    \n",
        "    # Acceleration magnitude    \n",
        "    amag = np.linalg.norm(accl_filt, axis=1)\n",
        "    \n",
        "    # Moving average filter\n",
        "    _input = np.append(np.ones(n_am - 1) * amag[0], amag)\n",
        "    _impresp = np.ones(n_am) / n_am\n",
        "    return np.convolve(_input, _impresp, mode='valid')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def estimation_param_combinations(param_ranges: dict) -> tuple:\n",
        "    \"\"\"\n",
        "    Generate the list of parameter combinations for estimating the pitch and \n",
        "    acceleration magnitude.\n",
        "    \"\"\"\n",
        "    # Pitch and accl. mag. estimation parameters\n",
        "    for _np in param_ranges[\"np\"]:\n",
        "        for _fc in param_ranges[\"fc\"]:\n",
        "            for _nc in param_ranges[\"nc\"]:\n",
        "                for _ath in param_ranges[\"deadband_th\"]:\n",
        "                    for _nam in param_ranges[\"nam\"]:\n",
        "                        yield (_np, _fc, _nc, _ath, _nam)\n",
        "\n",
        "\n",
        "# Generate all possible combinations of parameters.\n",
        "def generate_param_combinations(param_ranges: dict) -> dict:\n",
        "    \"\"\"\n",
        "    Generate all possible combinations of parameters.\n",
        "    \"\"\"\n",
        "    for _estparams in estimation_param_combinations(param_ranges):\n",
        "        for i1, _pmax in enumerate(param_ranges[\"p_th\"]):\n",
        "            for _pmin in param_ranges[\"p_th\"][:i1+1]:\n",
        "                for i2, _amax in enumerate(param_ranges[\"am_th\"]):\n",
        "                    for _amin in param_ranges[\"am_th\"][:i2+1]:\n",
        "                        yield {\n",
        "                            \"np\": int(_estparams[0]),\n",
        "                            \"fc\": _estparams[1],\n",
        "                            \"nc\": int(_estparams[2]),\n",
        "                            \"deadband_th\": _estparams[3],\n",
        "                            \"nam\": int(_estparams[4]),\n",
        "                            \"p_thmin\": _pmin,\n",
        "                            \"p_thmax\": _pmax,\n",
        "                            \"am_thmin\": _amin,\n",
        "                            \"am_thmax\": _amax\n",
        "                        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def apply_threshold_with_hysteresis(data: np.array, thmin: float, thmax: float,\n",
        "                                    out0: float=0):\n",
        "    \"\"\"\n",
        "    Applies threshold to the given data using the thmin and thmax thresholds.\n",
        "    \"\"\"\n",
        "    _out = np.zeros(len(data))\n",
        "    _out[0] = out0\n",
        "    for i in range(1, len(_out)):\n",
        "        if _out[i - 1] == 0:\n",
        "            _out[i] = 1 if data[i] >= thmax else 0\n",
        "        else:\n",
        "            _out[i] = 0 if data[i] < thmin else 1\n",
        "    return _out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def estimate_gmac(accl: np.array, accl_farm_inx: int, Fs: float, params: dict) -> np.array:\n",
        "    \"\"\"\n",
        "    Estimate GMAC for the given acceleration data and parameters.\n",
        "    \"\"\"\n",
        "    # Estimate pitch and acceleration magnitude\n",
        "    pitch = estimate_pitch(accl[:, accl_farm_inx], params[\"np\"])\n",
        "    accl_mag = estimate_accl_mag(accl, Fs, fc=params[\"fc\"], nc=params[\"nc\"],\n",
        "                                 deadband_th=params[\"deadband_th\"],\n",
        "                                 n_am=params[\"nam\"])\n",
        "    \n",
        "    # Compute GMAC\n",
        "    _pout = apply_threshold_with_hysteresis(pitch, params[\"p_thmin\"], params[\"p_thmax\"])\n",
        "    _amout = apply_threshold_with_hysteresis(accl_mag, params[\"am_thmin\"], params[\"am_thmax\"])\n",
        "    return _pout * _amout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_confusion_matrix(actual: np.array, estimated: np.array) -> np.array:\n",
        "    \"\"\"\n",
        "    Computes the components of the confusion matrix.\n",
        "    \"\"\"\n",
        "    actual = np.array(actual, dtype=int)\n",
        "    estimated = np.array(estimated, dtype=int)\n",
        "    return {\n",
        "        \"TN\": np.sum((actual + estimated) == 0), # TN\n",
        "        \"FP\": np.sum((1 - actual + estimated) == 2), # FP\n",
        "        \"FN\": np.sum((actual + 1 - estimated) == 2), # FN\n",
        "        \"TP\": np.sum((actual + estimated) == 2), # TP\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Parameter ranges for the grid search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "outdir = \"../data/output\"\n",
        "limbkey = \"left\"\n",
        "# Make directory if it does not exist\n",
        "pathlib.Path(outdir, limbkey).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# GMAC Parameter ranges\n",
        "gmac_param_ranges = {\n",
        "    \"np\": [1, Fs, 5*Fs],\n",
        "    \"fc\": [0.01, 0.1, 1],\n",
        "    \"nc\": [2, 4],\n",
        "    \"deadband_th\": [0, 0.068, 0.68],\n",
        "    \"nam\": [1, Fs, 5*Fs],\n",
        "    \"p_th\": np.arange(-90, 90, 30),\n",
        "    \"am_th\": [0, 1, 5, 10]\n",
        "}\n",
        "\n",
        "# Number of all possible combinations\n",
        "Ncombs = len(list(generate_param_combinations(gmac_param_ranges)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 242,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Combination:    34020/ 34020;  10/ 10;  2/ 2"
          ]
        }
      ],
      "source": [
        "# All parameter combinations.\n",
        "param_combs = list(generate_param_combinations(gmac_param_ranges))\n",
        "\n",
        "# Which limb?\n",
        "limbdf = datadf[limbkey]\n",
        "subjects = limbdf.subject.unique()\n",
        "\n",
        "# All param combinations.\n",
        "analysisdf = pd.DataFrame(columns=[\"subject\", \"pcinx\",\n",
        "                                   \"np\", \"fc\", \"nc\", \"deadband_th\", \"nam\",\n",
        "                                   \"p_thmin\", \"p_thmax\",\n",
        "                                   \"am_thmin\", \"am_thmax\",\n",
        "                                   \"TN\", \"FP\", \"FN\", \"TP\"])\n",
        "nrows_write = 1000\n",
        "for i1, _pc in enumerate(generate_param_combinations(gmac_param_ranges)):\n",
        "    # All subjects\n",
        "    for i2, _subj in enumerate(subjects):\n",
        "        _sinx= limbdf.subject == _subj\n",
        "        # All segments\n",
        "        segs = limbdf[_sinx].segment.unique()\n",
        "        _gmacs = []\n",
        "        for i3, _seg in enumerate(segs):\n",
        "            sys.stdout.write(f\"\\rCombination: {i1+1:8d}/{Ncombs:6d}; {i2+1:3d}/{len(subjects):3d}; {i3+1:2d}/{len(segs):2d}\")\n",
        "            sys.stdout.flush()\n",
        "            _ainx = _sinx & (limbdf.segment == _seg)\n",
        "            # Estimate GMAC\n",
        "            _accl = limbdf.loc[_ainx, ['ax', 'ay', 'az']].values\n",
        "            _gmacs.append(estimate_gmac(_accl, 0, Fs, _pc))\n",
        "        \n",
        "        # Estimate confusion matrix components\n",
        "        _perf = compute_confusion_matrix(actual=limbdf.loc[_sinx, \"gnd\"].values,\n",
        "                                         estimated=np.hstack(_gmacs))\n",
        "        # Update analysis DF\n",
        "        _rowdf = pd.DataFrame({\"subject\": _subj, \"pcinx\": i1} | _pc | _perf, index=[0])\n",
        "        analysisdf = pd.concat([analysisdf,_rowdf],\n",
        "                               axis=0, ignore_index=True)\n",
        "    # Save data regularly\n",
        "    if i1 > 0 and i1 % nrows_write == 0:\n",
        "        analysisdf.to_csv(pathlib.Path(outdir, limbkey, f\"analysisdf-{(i1 // nrows_write) - 1}.csv\"), index=False)\n",
        "        analysisdf = pd.DataFrame(columns=[\"subject\", \"pcinx\",\n",
        "                                           \"np\", \"fc\", \"nc\", \"deadband_th\", \"nam\",\n",
        "                                           \"p_thmin\", \"p_thmax\",\n",
        "                                           \"am_thmin\", \"am_thmax\",\n",
        "                                           \"TN\", \"FP\", \"FN\", \"TP\"])\n",
        "# Save whatever is left\n",
        "analysisdf.to_csv(pathlib.Path(outdir, limbkey, f\"analysisdf-{(i1 // nrows_write)}.csv\"), index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Find the most appropriate paramters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "def performance(yjvals: np.array) -> dict:\n",
        "    \"\"\"\n",
        "    Computes the performance of the given GMAC.\n",
        "    \"\"\"\n",
        "    q5, q50, q95 = np.percentile(yjvals, q=[5, 50, 95])\n",
        "    return {\n",
        "        \"median\": q50,\n",
        "        \"q5\": q5,\n",
        "        \"q95\": q95,\n",
        "        \"s90\": q95 - q5,\n",
        "        \"perf\": np.abs(q50 - 1) + 0.5 * (q95 - q5)\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subject</th>\n",
              "      <th>pcinx</th>\n",
              "      <th>np</th>\n",
              "      <th>fc</th>\n",
              "      <th>nc</th>\n",
              "      <th>deadband_th</th>\n",
              "      <th>nam</th>\n",
              "      <th>p_thmin</th>\n",
              "      <th>p_thmax</th>\n",
              "      <th>am_thmin</th>\n",
              "      <th>am_thmax</th>\n",
              "      <th>TN</th>\n",
              "      <th>FP</th>\n",
              "      <th>FN</th>\n",
              "      <th>TP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>6001</td>\n",
              "      <td>1</td>\n",
              "      <td>0.10</td>\n",
              "      <td>4</td>\n",
              "      <td>0.000</td>\n",
              "      <td>50</td>\n",
              "      <td>-30</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>7049</td>\n",
              "      <td>80</td>\n",
              "      <td>15878</td>\n",
              "      <td>1255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>6001</td>\n",
              "      <td>1</td>\n",
              "      <td>0.10</td>\n",
              "      <td>4</td>\n",
              "      <td>0.000</td>\n",
              "      <td>50</td>\n",
              "      <td>-30</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4902</td>\n",
              "      <td>4125</td>\n",
              "      <td>5006</td>\n",
              "      <td>8142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>6001</td>\n",
              "      <td>1</td>\n",
              "      <td>0.10</td>\n",
              "      <td>4</td>\n",
              "      <td>0.000</td>\n",
              "      <td>50</td>\n",
              "      <td>-30</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5210</td>\n",
              "      <td>2669</td>\n",
              "      <td>6776</td>\n",
              "      <td>7069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>6001</td>\n",
              "      <td>1</td>\n",
              "      <td>0.10</td>\n",
              "      <td>4</td>\n",
              "      <td>0.000</td>\n",
              "      <td>50</td>\n",
              "      <td>-30</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4605</td>\n",
              "      <td>3466</td>\n",
              "      <td>5838</td>\n",
              "      <td>6371</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>6001</td>\n",
              "      <td>1</td>\n",
              "      <td>0.10</td>\n",
              "      <td>4</td>\n",
              "      <td>0.000</td>\n",
              "      <td>50</td>\n",
              "      <td>-30</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>7551</td>\n",
              "      <td>1715</td>\n",
              "      <td>10608</td>\n",
              "      <td>6654</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>340195</th>\n",
              "      <td>7</td>\n",
              "      <td>12000</td>\n",
              "      <td>50</td>\n",
              "      <td>0.01</td>\n",
              "      <td>2</td>\n",
              "      <td>0.068</td>\n",
              "      <td>1</td>\n",
              "      <td>-90</td>\n",
              "      <td>-30</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>9268</td>\n",
              "      <td>1</td>\n",
              "      <td>14234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>340196</th>\n",
              "      <td>8</td>\n",
              "      <td>12000</td>\n",
              "      <td>50</td>\n",
              "      <td>0.01</td>\n",
              "      <td>2</td>\n",
              "      <td>0.068</td>\n",
              "      <td>1</td>\n",
              "      <td>-90</td>\n",
              "      <td>-30</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>7967</td>\n",
              "      <td>0</td>\n",
              "      <td>19449</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>340197</th>\n",
              "      <td>9</td>\n",
              "      <td>12000</td>\n",
              "      <td>50</td>\n",
              "      <td>0.01</td>\n",
              "      <td>2</td>\n",
              "      <td>0.068</td>\n",
              "      <td>1</td>\n",
              "      <td>-90</td>\n",
              "      <td>-30</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>21155</td>\n",
              "      <td>0</td>\n",
              "      <td>16160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>340198</th>\n",
              "      <td>10</td>\n",
              "      <td>12000</td>\n",
              "      <td>50</td>\n",
              "      <td>0.01</td>\n",
              "      <td>2</td>\n",
              "      <td>0.068</td>\n",
              "      <td>1</td>\n",
              "      <td>-90</td>\n",
              "      <td>-30</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>8690</td>\n",
              "      <td>1</td>\n",
              "      <td>13573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>340199</th>\n",
              "      <td>1</td>\n",
              "      <td>12000</td>\n",
              "      <td>50</td>\n",
              "      <td>0.01</td>\n",
              "      <td>2</td>\n",
              "      <td>0.068</td>\n",
              "      <td>1</td>\n",
              "      <td>-90</td>\n",
              "      <td>-30</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>8952</td>\n",
              "      <td>0</td>\n",
              "      <td>10580</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>340200 rows × 15 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        subject  pcinx  np    fc  nc  deadband_th  nam  p_thmin  p_thmax  \\\n",
              "0             2   6001   1  0.10   4        0.000   50      -30       30   \n",
              "1             3   6001   1  0.10   4        0.000   50      -30       30   \n",
              "2             4   6001   1  0.10   4        0.000   50      -30       30   \n",
              "3             5   6001   1  0.10   4        0.000   50      -30       30   \n",
              "4             6   6001   1  0.10   4        0.000   50      -30       30   \n",
              "...         ...    ...  ..   ...  ..          ...  ...      ...      ...   \n",
              "340195        7  12000  50  0.01   2        0.068    1      -90      -30   \n",
              "340196        8  12000  50  0.01   2        0.068    1      -90      -30   \n",
              "340197        9  12000  50  0.01   2        0.068    1      -90      -30   \n",
              "340198       10  12000  50  0.01   2        0.068    1      -90      -30   \n",
              "340199        1  12000  50  0.01   2        0.068    1      -90      -30   \n",
              "\n",
              "        am_thmin  am_thmax    TN     FP     FN     TP  \n",
              "0              0         1  7049     80  15878   1255  \n",
              "1              0         1  4902   4125   5006   8142  \n",
              "2              0         1  5210   2669   6776   7069  \n",
              "3              0         1  4605   3466   5838   6371  \n",
              "4              0         1  7551   1715  10608   6654  \n",
              "...          ...       ...   ...    ...    ...    ...  \n",
              "340195         0         0     3   9268      1  14234  \n",
              "340196         0         0     2   7967      0  19449  \n",
              "340197         0         0     3  21155      0  16160  \n",
              "340198         0         0     3   8690      1  13573  \n",
              "340199         0         0     2   8952      0  10580  \n",
              "\n",
              "[340200 rows x 15 columns]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Read all data and combine into a sigle DF\n",
        "files = glob.glob(pathlib.Path(outdir, limbkey, \"analysisdf*.csv\").as_posix())\n",
        "allanalysisdf = pd.read_csv(files[0], index_col=False)\n",
        "for _f in files[1:]:\n",
        "    _df = pd.read_csv(_f, index_col=False)\n",
        "    allanalysisdf = pd.concat([allanalysisdf, _df], axis=0, ignore_index=True)\n",
        "allanalysisdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute different performance metrics\n",
        "# Sensitivity\n",
        "allanalysisdf[\"sensitivity\"] = allanalysisdf.TP / (allanalysisdf.TP + allanalysisdf.FN)\n",
        "# Specificity\n",
        "allanalysisdf[\"specificity\"] = allanalysisdf.TN / (allanalysisdf.TN + allanalysisdf.FP)\n",
        "# Youden's J\n",
        "allanalysisdf[\"youden\"] = allanalysisdf.sensitivity + allanalysisdf.specificity - 1\n",
        "\n",
        "# Save analysis DF\n",
        "allanalysisdf.to_csv(pathlib.Path(outdir, limbkey, \"allanalysisdf.csv\"), index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Combination:    34020/ 34020;  10/ 10"
          ]
        }
      ],
      "source": [
        "# Subjects\n",
        "subjs = np.sort(allanalysisdf.subject.unique())\n",
        "q = 95\n",
        "\n",
        "# Optimization data frame\n",
        "optdf = pd.DataFrame(columns=[\"pcinx\", \"median\", \"q95\", \"q5\", \"s90\", \"cost\", \"testval\", \"testsubj\"])\n",
        "for _nc in range(Ncombs):\n",
        "    for sinx in range(len(subjs)):\n",
        "        sys.stdout.write(f\"\\rCombination: {_nc+1:8d}/{Ncombs:6d}; {sinx+1:3d}/{len(subjs):3d}\")\n",
        "        sys.stdout.flush()\n",
        "        testsubj = subjs[sinx]\n",
        "        trainsubj = subjs[~(subjs == testsubj)]\n",
        "        \n",
        "        # Find the best parameter combination for the training subjects.\n",
        "        _subjtraininx = allanalysisdf.subject.isin(trainsubj)\n",
        "        _subjtestinx = allanalysisdf.subject == testsubj\n",
        "        _inxtrain = allanalysisdf.pcinx == _nc\n",
        "        _inxtest = allanalysisdf.pcinx == _nc\n",
        "        \n",
        "        # Find the best parameter combination for the training subjects.\n",
        "        _yitrain = allanalysisdf.loc[_subjtraininx & _inxtrain, \"youden\"]\n",
        "        _yitest = allanalysisdf.loc[_subjtestinx & _inxtest, \"youden\"]\n",
        "        \n",
        "        # Performance vairables.\n",
        "        _perf = performance(_yitrain.values)\n",
        "        _perfdf = pd.DataFrame({\n",
        "            \"pcinx\": _nc,\n",
        "            \"median\": _perf[\"median\"],\n",
        "            \"q95\": _perf[\"q95\"],\n",
        "            \"q5\": _perf[\"q5\"],\n",
        "            \"s90\": _perf[\"s90\"],\n",
        "            \"cost\": _perf[\"perf\"],\n",
        "            \"testval\": _yitest.values,\n",
        "            \"testsubj\": testsubj\n",
        "        })\n",
        "        optdf = pd.concat([optdf, _perfdf], ignore_index=True)\n",
        "\n",
        "# Save the optimization data frame        \n",
        "optdf.to_csv(pathlib.Path(outdir, limbkey, f\"optdf.csv\"), index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Go through each validation subject, and choose the best training cost \n",
        "# parameter combination.\n",
        "bestparamsdf = pd.DataFrame(columns=[\"subj\", \"lbound\", \"bestpinx\", \"bestval\"])\n",
        "for _subj in optdf.testsubj.unique():\n",
        "    # _minval = np.min(optdf.loc[optdf.testsubj == _subj, \"cost\"])\n",
        "    _sinx = optdf.testsubj == _subj\n",
        "    _lbound = np.percentile(optdf.loc[optdf.testsubj == _subj, \"cost\"], .1)\n",
        "    _bpins = list(np.where(optdf.loc[_sinx, \"cost\"] <= _lbound)[0])\n",
        "    _bval = list(optdf.loc[_sinx, \"testval\"].values[_bpins])\n",
        "    bestparamsdf = pd.concat([bestparamsdf, \n",
        "                              pd.DataFrame({\"subj\": [_subj] * len(_bpins),\n",
        "                                            \"lbound\": [_lbound] * len(_bpins),\n",
        "                                            \"bestpinx\": _bpins,\n",
        "                                            \"bestval\": _bval})],\n",
        "                             ignore_index=True)\n",
        "# Save the optimization data frame\n",
        "bestparamsdf.to_csv(pathlib.Path(outdir, limbkey, f\"bestparamsdf.csv\"), index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ulfunc",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "afcba11dd2daf669f4680c8822ef2b15aa2b775fe4e3866448929bf9bb9938b0"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
